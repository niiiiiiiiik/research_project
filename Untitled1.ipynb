{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d35d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 827/827 [01:39<00:00,  8.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from yaml import safe_load\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dir = '/Users/nikhil/Desktop/final_research_project_git/research_project/2024_male'\n",
    "\n",
    "\n",
    "if not os.path.isdir(data_dir):\n",
    "    print(f\"Directory '{data_dir}' does not exist.\")\n",
    "else:\n",
    "    filenames = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith('.yaml')]\n",
    "    dfs = []\n",
    "\n",
    "    for counter, file in tqdm(enumerate(filenames), desc=\"Processing files\", total=len(filenames)):\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8') as f:\n",
    "                df = pd.json_normalize(safe_load(f))\n",
    "                df['match_id'] = counter + 1\n",
    "                dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file}': {e}\")\n",
    "\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    pickle.dump(final_df, open('matches.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc23e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pickle.load(open('matches.pkl', 'rb'))\n",
    "delivery_data = []\n",
    "\n",
    "for index, row in matches.iterrows():\n",
    "    for delivery in row['innings'][0]['1st innings']['deliveries']:\n",
    "        for ball_number, details in delivery.items():\n",
    "            delivery_data.append({\n",
    "                'match_id': row['match_id'],\n",
    "                'batting_team': row['innings'][0]['1st innings']['team'],\n",
    "                'ball': ball_number,\n",
    "                'batsman': details['batsman'],\n",
    "                'bowler': details['bowler'],\n",
    "                'runs': details['runs']['total'],\n",
    "                'player_dismissed': details.get('wicket', {}).get('player_out', '0'),\n",
    "                'city': row['info.city'],\n",
    "                'venue': row['info.venue']\n",
    "            })\n",
    "\n",
    "delivery_df = pd.DataFrame(delivery_data)\n",
    "delivery_df.to_csv('delivery_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecb73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/yt14z40j2lb2lz548fqr3v9m0000gn/T/ipykernel_17661/3826655051.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  matches['Date'] = pd.to_datetime(matches['info.dates'].str[0], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Load the data\n",
    "delivery_df = pd.read_csv('delivery_data.csv')\n",
    "matches = pd.read_pickle('matches.pkl')\n",
    "\n",
    "# Further process match details\n",
    "matches['Date'] = pd.to_datetime(matches['info.dates'].str[0], errors='coerce')\n",
    "\n",
    "# Merge delivery data with match details\n",
    "combined_df = pd.merge(delivery_df, matches, on='match_id', how='inner')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c8cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'meta.data_version',\n",
    "    'meta.created',\n",
    "    'meta.revision',\n",
    "    'info.outcome.bowl_out',\n",
    "    'info.bowl_out',\n",
    "    'info.supersubs.South Africa',\n",
    "    'info.supersubs.New Zealand',\n",
    "    'info.outcome.eliminator',\n",
    "    'info.outcome.result',\n",
    "    'info.outcome.method',\n",
    "    'info.neutral_venue',\n",
    "    'info.match_type_number',\n",
    "    'info.outcome.by.runs',\n",
    "    'info.outcome.by.wickets'\n",
    "]\n",
    "\n",
    "# Use set intersection to find columns that actually exist in your DataFrame\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in combined_df.columns]\n",
    "\n",
    "# Drop only the existing columns\n",
    "combined_df.drop(columns=existing_columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e615cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=combined_df[combined_df['info.gender']=='male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf44fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['info.gender'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235b0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['info.overs'] == 20]\n",
    "combined_df.drop(columns=['info.overs','info.match_type'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e36d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowl(row):\n",
    "    for team in row['info.teams']:\n",
    "        if team != row['batting_team']:\n",
    "            return team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0360db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['bowling_team'] = combined_df.apply(bowl,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce11bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\n",
    "    'Australia',\n",
    "    'India',\n",
    "    'Bangladesh',\n",
    "    'New Zealand',\n",
    "    'South Africa',\n",
    "    'England',\n",
    "    'West Indies',\n",
    "    'Afghanistan',\n",
    "    'Pakistan',\n",
    "    'Sri Lanka'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a75fb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['batting_team'].isin(teams)]\n",
    "combined_df = combined_df[combined_df['bowling_team'].isin(teams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d372de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = ['match_id', 'batting_team', 'ball', 'batsman', 'bowler', 'runs',\n",
    "           'player_dismissed', 'city', 'venue', 'innings', 'info.city',\n",
    "           'info.dates', 'info.outcome.winner', 'info.player_of_match',\n",
    "           'info.toss.decision', 'info.toss.winner', 'info.umpires', 'info.venue',\n",
    "           'Date', 'bowling_team']\n",
    "\n",
    "# Create a dictionary to map old column names to new column names where 'info.' is removed\n",
    "rename_dict = {col: col.replace('info.', '') for col in columns if 'info.' in col}\n",
    "\n",
    "# Renaming the columns in the DataFrame\n",
    "combined_df.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a4ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format without indexing if it's already a string or datetime\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dab6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if isinstance(combined_df['info.teams'].iloc[0], list):\n",
    "    combined_df[['Team 1', 'Team 2']] = pd.DataFrame(combined_df['info.teams'].tolist(), index=combined_df.index)\n",
    "    combined_df.drop(columns='info.teams', inplace=True)\n",
    "else:\n",
    "    print(\"Teams column is not in expected list format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d55cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {\n",
    "    'toss.winner': 'toss_winner',\n",
    "    'outcome.winner': 'match_winner',\n",
    "    'player_of_match': 'player_of_the_match',  \n",
    "    'toss.decision': 'toss_decision'\n",
    "}\n",
    "\n",
    "\n",
    "combined_df.rename(columns=rename_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d4a9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns='innings', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d373d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns='umpires', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ca17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizing columns to group related data together\n",
    "organized_columns = [\n",
    "    'match_id',\n",
    "    'Team 1', 'Team 2',  # Grouping team information\n",
    "    'batting_team', 'bowling_team',  # Further grouping team interaction\n",
    "    'ball',   # Game progression details\n",
    "    'batsman', 'bowler', 'runs', 'player_dismissed',  # Delivery-specific details\n",
    "    'city', 'venue', 'Date',  # Location and time of the match\n",
    "    'toss_winner', 'toss_decision',  # Toss details\n",
    "    'match_winner', 'player_of_the_match' # Outcome details\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "combined_df = combined_df[organized_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de8ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate columns by selecting the first occurrence\n",
    "combined_df = combined_df.loc[:,~combined_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7692ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = np.where(combined_df['city'].isnull(),combined_df['venue'].str.split().apply(lambda x:x[0]),combined_df['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e60cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['city'] = cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41041d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the DataFrame to find rows where 'player_of_the_match' is null\n",
    "null_potm_df = combined_df[combined_df['player_of_the_match'].isnull()]\n",
    "\n",
    "# Count the initial number of rows for reference\n",
    "initial_count = combined_df.shape[0]\n",
    "\n",
    "# Drop rows where 'player_of_the_match' is NaN\n",
    "combined_df.dropna(subset=['player_of_the_match'], inplace=True)\n",
    "\n",
    "# Count the final number of rows to calculate how many were dropped\n",
    "final_count = combined_df.shape[0]\n",
    "rows_dropped = initial_count - final_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d41b5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/yt14z40j2lb2lz548fqr3v9m0000gn/T/ipykernel_17661/3779091949.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.cumsum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  combined_df['current_score'] = combined_df.groupby('match_id').cumsum()['runs']\n"
     ]
    }
   ],
   "source": [
    "combined_df['current_score'] = combined_df.groupby('match_id').cumsum()['runs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ca684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['over'] = combined_df['ball'].apply(lambda x:str(x).split(\".\")[0])\n",
    "combined_df['ball_no'] = combined_df['ball'].apply(lambda x:str(x).split(\".\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b3d2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['balls_bowled'] = (combined_df['over'].astype('int')*6) + combined_df['ball_no'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d8facff",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['balls_left'] = 120 - combined_df['balls_bowled']\n",
    "combined_df['balls_left'] = combined_df['balls_left'].apply(lambda x:0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e3d4750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/yt14z40j2lb2lz548fqr3v9m0000gn/T/ipykernel_17661/380341676.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.cumsum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  combined_df['player_dismissed'] = combined_df.groupby('match_id').cumsum()['player_dismissed']\n"
     ]
    }
   ],
   "source": [
    "combined_df['player_dismissed'] = combined_df['player_dismissed'].apply(lambda x:0 if x=='0' else 1)\n",
    "combined_df['player_dismissed'] = combined_df['player_dismissed'].astype('int')\n",
    "combined_df['player_dismissed'] = combined_df.groupby('match_id').cumsum()['player_dismissed']\n",
    "combined_df['wickets_left'] = 10 - combined_df['player_dismissed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca17a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['crr'] = (combined_df['current_score']*6)/combined_df['balls_bowled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cdb945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/yt14z40j2lb2lz548fqr3v9m0000gn/T/ipykernel_17661/1897754388.py:6: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['Date', 'Team 1', 'Team 2', 'batsman', 'batting_team', 'bowler',\n",
      "       'bowling_team', 'city', 'match_winner', 'player_of_the_match',\n",
      "       'toss_decision', 'toss_winner', 'venue'],\n",
      "      dtype='object')\n",
      "  last_five.extend(groups.get_group(id).rolling(window=30).sum()['runs'].values.tolist())\n",
      "/var/folders/zk/yt14z40j2lb2lz548fqr3v9m0000gn/T/ipykernel_17661/1897754388.py:6: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['Date', 'Team 1', 'Team 2', 'batsman', 'batting_team', 'bowler',\n",
      "       'bowling_team', 'city', 'player_of_the_match', 'toss_decision',\n",
      "       'toss_winner', 'venue'],\n",
      "      dtype='object')\n",
      "  last_five.extend(groups.get_group(id).rolling(window=30).sum()['runs'].values.tolist())\n"
     ]
    }
   ],
   "source": [
    "groups = combined_df.groupby('match_id')\n",
    "\n",
    "match_ids = combined_df['match_id'].unique()\n",
    "last_five = []\n",
    "for id in match_ids:\n",
    "    last_five.extend(groups.get_group(id).rolling(window=30).sum()['runs'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "821e206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['last_five'] = last_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b992a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df.loc[:, 'run_rate'] = combined_df['current_score'] / (120 - combined_df['balls_left']) * 6\n",
    "combined_df.loc[:, 'wickets_rate'] = combined_df['wickets_left'] / (120 - combined_df['balls_left']) * 6\n",
    "\n",
    "# Using vectorized operations to create the Pressure Factor\n",
    "combined_df.loc[:, 'pressure_factor'] = combined_df.apply(\n",
    "    lambda row: row['last_five'] / (10 - row['wickets_left']) if row['wickets_left'] < 10 else row['last_five'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3488d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite or NaN values which may have been introduced\n",
    "combined_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "combined_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3faf52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching weather data: 100%|██████████| 5994/5994 [00:10<00:00, 581.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id               0\n",
      "Team 1                 0\n",
      "Team 2                 0\n",
      "batting_team           0\n",
      "bowling_team           0\n",
      "ball                   0\n",
      "batsman                0\n",
      "bowler                 0\n",
      "runs                   0\n",
      "player_dismissed       0\n",
      "city                   0\n",
      "venue                  0\n",
      "Date                   0\n",
      "toss_winner            0\n",
      "toss_decision          0\n",
      "match_winner           0\n",
      "player_of_the_match    0\n",
      "current_score          0\n",
      "over                   0\n",
      "ball_no                0\n",
      "balls_bowled           0\n",
      "balls_left             0\n",
      "wickets_left           0\n",
      "crr                    0\n",
      "last_five              0\n",
      "run_rate               0\n",
      "wickets_rate           0\n",
      "pressure_factor        0\n",
      "max_tempC              0\n",
      "min_tempC              0\n",
      "sun_hour               0\n",
      "total_precip_mm        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to fetch weather data\n",
    "def get_weather_data(api_key, location, date):\n",
    "    url = f\"https://api.worldweatheronline.com/premium/v1/past-weather.ashx\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        'date': date.strftime('%Y-%m-%d'),  # Ensure date is in YYYY-MM-DD format\n",
    "        'format': 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'weather' in data['data']:\n",
    "            return data['data']['weather'][0]\n",
    "        else:\n",
    "            print(f\"No weather data for {location} on {date}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error fetching data for {location} on {date}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "api_key = 'cc6e60b3cb3c4b788ff123310241607'\n",
    "\n",
    "# Ensure no missing values in key columns before fetching weather data\n",
    "assert combined_df[['match_id', 'city', 'Date']].isnull().sum().sum() == 0\n",
    "\n",
    "# Dictionary to store fetched weather data for each match_id\n",
    "weather_data_cache = {}\n",
    "\n",
    "# Fetch and add weather data\n",
    "weather_data = []\n",
    "for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0], desc=\"Fetching weather data\"):\n",
    "    match_id = row['match_id']\n",
    "    if match_id not in weather_data_cache:\n",
    "        weather = get_weather_data(api_key, row['city'], row['Date'])\n",
    "        if weather:\n",
    "            weather_info = {\n",
    "                'match_id': match_id,\n",
    "                'max_tempC': weather.get('maxtempC', None),\n",
    "                'min_tempC': weather.get('mintempC', None),\n",
    "                'sun_hour': weather.get('sunHour', None),\n",
    "                'total_precip_mm': weather.get('totalprecipMM', None)\n",
    "            }\n",
    "            weather_data_cache[match_id] = weather_info\n",
    "        else:\n",
    "            weather_data_cache[match_id] = {\n",
    "                'match_id': match_id,\n",
    "                'max_tempC': None,\n",
    "                'min_tempC': None,\n",
    "                'sun_hour': None,\n",
    "                'total_precip_mm': None\n",
    "            }\n",
    "    \n",
    "    weather_data.append(weather_data_cache[match_id])\n",
    "\n",
    "weather_df = pd.DataFrame(weather_data)\n",
    "\n",
    "# Convert weather data columns to numeric, handling errors\n",
    "weather_df['max_tempC'] = pd.to_numeric(weather_df['max_tempC'], errors='coerce')\n",
    "weather_df['min_tempC'] = pd.to_numeric(weather_df['min_tempC'], errors='coerce')\n",
    "weather_df['sun_hour'] = pd.to_numeric(weather_df['sun_hour'], errors='coerce')\n",
    "weather_df['total_precip_mm'] = pd.to_numeric(weather_df['total_precip_mm'], errors='coerce')\n",
    "\n",
    "# Merge with combined_df\n",
    "combined_df = pd.merge(combined_df, weather_df, on='match_id', how='left')\n",
    "\n",
    "# Handle missing data\n",
    "combined_df['max_tempC'].fillna(combined_df['max_tempC'].mean(), inplace=True)\n",
    "combined_df['min_tempC'].fillna(combined_df['min_tempC'].mean(), inplace=True)\n",
    "combined_df['sun_hour'].fillna(combined_df['sun_hour'].mean(), inplace=True)\n",
    "combined_df['total_precip_mm'].fillna(0, inplace=True)  # Assuming 0 precipitation if data is missing\n",
    "\n",
    "print(combined_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87c514fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['total_precip_mm'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dd0ce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nazmul Hossain Shanto']\n",
      "['V Kohli']\n",
      "['Naveen-ul-Haq']\n",
      "['Gulbadin Naib']\n",
      "['AD Mathews']\n",
      "['MS Chapman']\n",
      "['RL Chase']\n",
      "['FH Allen']\n",
      "['BA King']\n",
      "['Iftikhar Ahmed']\n",
      "['N Thushara']\n",
      "['J Charles']\n",
      "['M Pathirana']\n",
      "['PJ Cummins']\n",
      "['RG Sharma']\n",
      "['AD Russell']\n",
      "['N Pooran']\n",
      "['PD Salt']\n",
      "['MR Marsh']\n",
      "['S Dube']\n",
      "['AR Patel']\n",
      "['M Jansen']\n",
      "['Q de Kock']\n",
      "['H Klaasen']\n",
      "['A Zampa']\n",
      "['HH Pandya']\n",
      "['DJ Mitchell']\n",
      "['Rishad Hossain']\n",
      "['Rahmanullah Gurbaz']\n",
      "['JC Buttler']\n",
      "['MW Short']\n",
      "[\"W O'Rourke\"]\n",
      "['A Nortje']\n",
      "['JJ Bumrah']\n",
      "['T Shamsi']\n",
      "['DA Warner']\n",
      "['GJ Maxwell']\n",
      "['SA Yadav']\n",
      "['KIC Asalanka']\n",
      "['Shaheen Shah Afridi']\n",
      "['AU Rashid']\n",
      "['SE Rutherford']\n"
     ]
    }
   ],
   "source": [
    "# Set to collect unique representations of the lists\n",
    "unique_lists = set()\n",
    "\n",
    "# Loop through the column and add unique list types to the set\n",
    "for item in combined_df['player_of_the_match']:\n",
    "    if isinstance(item, list):\n",
    "        # Convert list to a tuple (which is hashable and can be added to a set)\n",
    "        unique_lists.add(tuple(item))\n",
    "\n",
    "# Print each unique list found in the column\n",
    "for unique_list in unique_lists:\n",
    "    print(list(unique_list))  # Convert tuple back to list for nicer formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbf43976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of names to a single underscore-separated string\n",
    "combined_df['player_of_the_match'] = combined_df['player_of_the_match'].apply(\n",
    "    lambda x: '_'.join(x).replace(' ', '_') if isinstance(x, list) else x.replace(' ', '_')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67c2606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert no entries are lists\n",
    "assert not combined_df['player_of_the_match'].apply(isinstance, args=(list,)).any(), \"Some entries are still lists.\"\n",
    "\n",
    "# Optional: Check if all entries are strings now\n",
    "assert combined_df['player_of_the_match'].apply(isinstance, args=(str,)).all(), \"Not all entries are strings.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ed73920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>Team 1</th>\n",
       "      <th>Team 2</th>\n",
       "      <th>batting_team</th>\n",
       "      <th>bowling_team</th>\n",
       "      <th>ball</th>\n",
       "      <th>batsman</th>\n",
       "      <th>bowler</th>\n",
       "      <th>runs</th>\n",
       "      <th>player_dismissed</th>\n",
       "      <th>...</th>\n",
       "      <th>balls_left</th>\n",
       "      <th>wickets_left</th>\n",
       "      <th>crr</th>\n",
       "      <th>last_five</th>\n",
       "      <th>run_rate</th>\n",
       "      <th>wickets_rate</th>\n",
       "      <th>pressure_factor</th>\n",
       "      <th>max_tempC</th>\n",
       "      <th>min_tempC</th>\n",
       "      <th>sun_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Q de Kock</td>\n",
       "      <td>Tanzim Hasan Sakib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Q de Kock</td>\n",
       "      <td>Tanzim Hasan Sakib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Q de Kock</td>\n",
       "      <td>Tanzim Hasan Sakib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Q de Kock</td>\n",
       "      <td>Tanzim Hasan Sakib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Q de Kock</td>\n",
       "      <td>Tanzim Hasan Sakib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id        Team 1      Team 2  batting_team bowling_team  ball  \\\n",
       "0        10  South Africa  Bangladesh  South Africa   Bangladesh   0.1   \n",
       "1        10  South Africa  Bangladesh  South Africa   Bangladesh   0.1   \n",
       "2        10  South Africa  Bangladesh  South Africa   Bangladesh   0.1   \n",
       "3        10  South Africa  Bangladesh  South Africa   Bangladesh   0.1   \n",
       "4        10  South Africa  Bangladesh  South Africa   Bangladesh   0.1   \n",
       "\n",
       "     batsman              bowler  runs  player_dismissed  ... balls_left  \\\n",
       "0  Q de Kock  Tanzim Hasan Sakib     0                 0  ...        119   \n",
       "1  Q de Kock  Tanzim Hasan Sakib     0                 0  ...        119   \n",
       "2  Q de Kock  Tanzim Hasan Sakib     0                 0  ...        119   \n",
       "3  Q de Kock  Tanzim Hasan Sakib     0                 0  ...        119   \n",
       "4  Q de Kock  Tanzim Hasan Sakib     0                 0  ...        119   \n",
       "\n",
       "  wickets_left  crr last_five run_rate wickets_rate pressure_factor  \\\n",
       "0           10  0.0       0.0      0.0         60.0             0.0   \n",
       "1           10  0.0       0.0      0.0         60.0             0.0   \n",
       "2           10  0.0       0.0      0.0         60.0             0.0   \n",
       "3           10  0.0       0.0      0.0         60.0             0.0   \n",
       "4           10  0.0       0.0      0.0         60.0             0.0   \n",
       "\n",
       "   max_tempC min_tempC sun_hour  \n",
       "0         24        15     15.0  \n",
       "1         24        15     15.0  \n",
       "2         24        15     15.0  \n",
       "3         24        15     15.0  \n",
       "4         24        15     15.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicated rows\n",
    "duplicates = combined_df[combined_df.duplicated(keep=False)]  # 'keep=False' marks all duplicates as True\n",
    "\n",
    "# Display the duplicated rows to understand what data is being repeated\n",
    "duplicates.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8955afe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame size: (739346, 31)\n",
      "Cleaned DataFrame size: (5994, 31)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates, keeping the first occurrence\n",
    "cleaned_df = combined_df.drop_duplicates(keep='first')\n",
    "\n",
    "# Verifying the change\n",
    "print(f\"Original DataFrame size: {combined_df.shape}\")\n",
    "print(f\"Cleaned DataFrame size: {cleaned_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28ca6740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any duplicates left\n",
    "remaining_duplicates = cleaned_df.duplicated().sum()\n",
    "print(f\"Remaining duplicates after cleaning: {remaining_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72e28745",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('cleaned_df_with_temp_not_used.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75150599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
